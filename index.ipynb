{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\windows\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./helpers/data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 4)\n",
      "(2, 5, 4)\n",
      "(7, 7, 4)\n",
      "(43, 8, 4)\n",
      "(35, 9, 4)\n",
      "(18, 10, 4)\n",
      "(228, 11, 4)\n",
      "(506, 12, 4)\n",
      "(628, 13, 4)\n",
      "(431, 14, 4)\n",
      "(1870, 15, 4)\n",
      "(4256, 16, 4)\n",
      "(7292, 17, 4)\n",
      "(5418, 19, 4)\n",
      "(37133, 20, 4)\n",
      "(42408, 23, 4)\n"
     ]
    }
   ],
   "source": [
    "my_dict = dict()\n",
    "for d in data:\n",
    "    if d.shape[0] not in my_dict:\n",
    "        my_dict[d.shape[0]] = []\n",
    "    my_dict[d.shape[0]].append(d)\n",
    "    \n",
    "for k in my_dict:\n",
    "    my_dict[k] = np.stack(my_dict[k])\n",
    "    print(my_dict[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "lstm_units = 50\n",
    "vocab_size = 4\n",
    "seq_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGNetEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, lstm_units):\n",
    "        super(CFGNetEncoder, self).__init__()\n",
    "        self.lstm_units = lstm_units\n",
    "        self.recurrent = tf.keras.layers.LSTM(lstm_units)\n",
    "        self.dense1 = tf.keras.layers.Dense(lstm_units * 2)\n",
    "        self.dense2 = tf.keras.layers.Dense(lstm_units * 2)\n",
    "    \n",
    "    def _sample(self, z_mean, z_log_sigma):\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        latent_dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch_size, latent_dim))\n",
    "        return z_mean + tf.keras.backend.exp(z_log_sigma) * epsilon\n",
    "    \n",
    "    def call(self, v):\n",
    "        out = self.recurrent(v)\n",
    "        z_mean = self.dense1(out)\n",
    "        z_log_sigma = self.dense2(out)\n",
    "        return self._sample(z_mean, z_log_sigma)\n",
    "\n",
    "# temp_encoder = CFGNetEncoder(lstm_units)\n",
    "# y = tf.zeros((batch_size, lstm_units, vocab_size))\n",
    "# state = temp_encoder(y)\n",
    "# state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGNetDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, lstm_units, vocab_size):\n",
    "        super(CFGNetDecoder, self).__init__()\n",
    "        self.lstm_units = lstm_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.recurrent = tf.keras.layers.LSTM(lstm_units, return_sequences=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    " \n",
    "    def call(self, seq_len, state):\n",
    "        states = tf.split(state, num_or_size_splits=2, axis=1)\n",
    "        hidden_state_shape = tf.shape(states[0])\n",
    "        batch_size = hidden_state_shape[0]\n",
    "        vocab_size = self.vocab_size\n",
    "        v = tf.zeros((batch_size,seq_len,vocab_size))\n",
    "        out = self.recurrent(v, initial_state=states)\n",
    "        return self.dense(out)\n",
    "\n",
    "# temp_decoder = CFGNetDecoder(lstm_units, vocab_size)\n",
    "# state = tf.zeros((batch_size, lstm_units * 2))\n",
    "# out = temp_decoder(seq_len, state)\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGNetAutoencoder(tf.keras.Model):\n",
    "    def __init__(self, lstm_units,vocab_size):\n",
    "        super(CFGNetAutoencoder, self).__init__()\n",
    "        self.lstm_units = lstm_units\n",
    "        self.vocab_size = vocab_size\n",
    "        self.encoder = CFGNetEncoder(lstm_units)\n",
    "        self.decoder = CFGNetDecoder(lstm_units, vocab_size)\n",
    "\n",
    "    def call(self, v):\n",
    "        seq_len = tf.shape(v)[1]\n",
    "        state = self.encoder(v)\n",
    "        return self.decoder(seq_len, state)\n",
    "\n",
    "# temp_autoencoder = CFGNetAutoencoder(lstm_units, vocab_size)\n",
    "# v = tf.zeros((batch_size, seq_len, vocab_size))\n",
    "# out = temp_autoencoder(v)\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42408, 23, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_use = my_dict[23]\n",
    "data_to_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_net_autoencoder = CFGNetAutoencoder(100, data_to_use.shape[2])\n",
    "cfg_net_autoencoder.compile(loss='categorical_crossentropy', optimizer='RMSprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4256/4256 [==============================] - 1s 338us/step - loss: 5.7847\n",
      "Epoch 2/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8434\n",
      "Epoch 3/1000\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.494001). Check your callbacks.\n",
      "4256/4256 [==============================] - 1s 219us/step - loss: 5.8133\n",
      "Epoch 4/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8179\n",
      "Epoch 5/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7689\n",
      "Epoch 6/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7886\n",
      "Epoch 7/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7819\n",
      "Epoch 8/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8034\n",
      "Epoch 9/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8000\n",
      "Epoch 10/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7804\n",
      "Epoch 11/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7650\n",
      "Epoch 12/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8005\n",
      "Epoch 13/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8470\n",
      "Epoch 14/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7968\n",
      "Epoch 15/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7963\n",
      "Epoch 16/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7607\n",
      "Epoch 17/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8081\n",
      "Epoch 18/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7632\n",
      "Epoch 19/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8224\n",
      "Epoch 20/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7804\n",
      "Epoch 21/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.8417\n",
      "Epoch 22/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8336\n",
      "Epoch 23/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8240\n",
      "Epoch 24/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7728\n",
      "Epoch 25/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7570\n",
      "Epoch 26/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8057\n",
      "Epoch 27/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8154\n",
      "Epoch 28/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8028\n",
      "Epoch 29/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7826\n",
      "Epoch 30/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7986\n",
      "Epoch 31/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8303\n",
      "Epoch 32/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.8100\n",
      "Epoch 33/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.7187\n",
      "Epoch 34/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8625\n",
      "Epoch 35/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7434\n",
      "Epoch 36/1000\n",
      "4256/4256 [==============================] - 1s 126us/step - loss: 5.8063\n",
      "Epoch 37/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7953\n",
      "Epoch 38/1000\n",
      "4256/4256 [==============================] - 1s 141us/step - loss: 5.8200\n",
      "Epoch 39/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7518\n",
      "Epoch 40/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7786\n",
      "Epoch 41/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8581\n",
      "Epoch 42/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7752\n",
      "Epoch 43/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8362\n",
      "Epoch 44/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8394\n",
      "Epoch 45/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8625\n",
      "Epoch 46/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7519\n",
      "Epoch 47/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8571\n",
      "Epoch 48/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7767\n",
      "Epoch 49/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7829\n",
      "Epoch 50/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8255\n",
      "Epoch 51/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8325\n",
      "Epoch 52/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8790\n",
      "Epoch 53/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7895\n",
      "Epoch 54/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.8148\n",
      "Epoch 55/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.7893\n",
      "Epoch 56/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8656\n",
      "Epoch 57/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8201\n",
      "Epoch 58/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7839\n",
      "Epoch 59/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7744\n",
      "Epoch 60/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.8681\n",
      "Epoch 61/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7718\n",
      "Epoch 62/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7622\n",
      "Epoch 63/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7674\n",
      "Epoch 64/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8075\n",
      "Epoch 65/1000\n",
      "4256/4256 [==============================] - 1s 126us/step - loss: 5.7241\n",
      "Epoch 66/1000\n",
      "4256/4256 [==============================] - 1s 127us/step - loss: 5.8487\n",
      "Epoch 67/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7792\n",
      "Epoch 68/1000\n",
      "4256/4256 [==============================] - 1s 170us/step - loss: 5.8105\n",
      "Epoch 69/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.8204\n",
      "Epoch 70/1000\n",
      "4256/4256 [==============================] - 1s 150us/step - loss: 5.8560\n",
      "Epoch 71/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8420\n",
      "Epoch 72/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7721\n",
      "Epoch 73/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7830\n",
      "Epoch 74/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7431\n",
      "Epoch 75/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8830\n",
      "Epoch 76/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8196\n",
      "Epoch 77/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7993\n",
      "Epoch 78/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7709\n",
      "Epoch 79/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8347\n",
      "Epoch 80/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8227\n",
      "Epoch 81/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8737\n",
      "Epoch 82/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7587\n",
      "Epoch 83/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8253\n",
      "Epoch 84/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8174\n",
      "Epoch 85/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8758\n",
      "Epoch 86/1000\n",
      "4256/4256 [==============================] - 1s 117us/step - loss: 5.7940\n",
      "Epoch 87/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7482\n",
      "Epoch 88/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7753\n",
      "Epoch 89/1000\n",
      "4256/4256 [==============================] - 1s 128us/step - loss: 5.8289\n",
      "Epoch 90/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7678\n",
      "Epoch 91/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8348\n",
      "Epoch 92/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7029\n",
      "Epoch 94/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7632\n",
      "Epoch 95/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7843\n",
      "Epoch 96/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7819\n",
      "Epoch 97/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7573\n",
      "Epoch 98/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8792\n",
      "Epoch 99/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7553\n",
      "Epoch 100/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8513\n",
      "Epoch 101/1000\n",
      "4256/4256 [==============================] - 1s 136us/step - loss: 5.8062\n",
      "Epoch 102/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8269\n",
      "Epoch 103/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7769\n",
      "Epoch 104/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8330\n",
      "Epoch 105/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7993\n",
      "Epoch 106/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8065\n",
      "Epoch 107/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8154\n",
      "Epoch 108/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7426\n",
      "Epoch 109/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7803\n",
      "Epoch 110/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8075\n",
      "Epoch 111/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8041\n",
      "Epoch 112/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8126\n",
      "Epoch 113/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7111\n",
      "Epoch 114/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7473\n",
      "Epoch 115/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8660\n",
      "Epoch 116/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7504\n",
      "Epoch 117/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7901\n",
      "Epoch 118/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8696\n",
      "Epoch 119/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8097\n",
      "Epoch 120/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8971\n",
      "Epoch 121/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8118\n",
      "Epoch 122/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8658\n",
      "Epoch 123/1000\n",
      "4256/4256 [==============================] - 1s 128us/step - loss: 5.8129\n",
      "Epoch 124/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8207\n",
      "Epoch 125/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.7866\n",
      "Epoch 126/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7614\n",
      "Epoch 127/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7661\n",
      "Epoch 128/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8064\n",
      "Epoch 129/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7801\n",
      "Epoch 130/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8228\n",
      "Epoch 131/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7626\n",
      "Epoch 132/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7707\n",
      "Epoch 133/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7840\n",
      "Epoch 134/1000\n",
      "4256/4256 [==============================] - 1s 172us/step - loss: 5.7890\n",
      "Epoch 135/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8647\n",
      "Epoch 136/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7975\n",
      "Epoch 137/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7954\n",
      "Epoch 138/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8731\n",
      "Epoch 139/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8432\n",
      "Epoch 140/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8182\n",
      "Epoch 141/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7871\n",
      "Epoch 142/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8473\n",
      "Epoch 143/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8106\n",
      "Epoch 144/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7885\n",
      "Epoch 145/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.7792\n",
      "Epoch 146/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8718\n",
      "Epoch 147/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8178\n",
      "Epoch 148/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8279\n",
      "Epoch 149/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7529\n",
      "Epoch 150/1000\n",
      "4256/4256 [==============================] - 1s 146us/step - loss: 5.7573\n",
      "Epoch 151/1000\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.928009). Check your callbacks.\n",
      "4256/4256 [==============================] - 1s 339us/step - loss: 5.8122\n",
      "Epoch 152/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8248\n",
      "Epoch 153/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8075\n",
      "Epoch 154/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8458\n",
      "Epoch 155/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7834\n",
      "Epoch 156/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7708\n",
      "Epoch 157/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.9004\n",
      "Epoch 158/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7291\n",
      "Epoch 159/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8427\n",
      "Epoch 160/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7801\n",
      "Epoch 161/1000\n",
      "4256/4256 [==============================] - 1s 133us/step - loss: 5.7924\n",
      "Epoch 162/1000\n",
      "4256/4256 [==============================] - 1s 128us/step - loss: 5.8992\n",
      "Epoch 163/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7855\n",
      "Epoch 164/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7972\n",
      "Epoch 165/1000\n",
      "4256/4256 [==============================] - 1s 166us/step - loss: 5.8120\n",
      "Epoch 166/1000\n",
      "4256/4256 [==============================] - 1s 124us/step - loss: 5.8035\n",
      "Epoch 167/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7508\n",
      "Epoch 168/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8598\n",
      "Epoch 169/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7869\n",
      "Epoch 170/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8400\n",
      "Epoch 171/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7318\n",
      "Epoch 172/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8397\n",
      "Epoch 173/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7754\n",
      "Epoch 174/1000\n",
      "4256/4256 [==============================] - 0s 105us/step - loss: 5.8047\n",
      "Epoch 175/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7906\n",
      "Epoch 176/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8294\n",
      "Epoch 177/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7471\n",
      "Epoch 178/1000\n",
      "4256/4256 [==============================] - 1s 124us/step - loss: 5.8330\n",
      "Epoch 179/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8270\n",
      "Epoch 180/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8066\n",
      "Epoch 181/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8385\n",
      "Epoch 182/1000\n",
      "4256/4256 [==============================] - 1s 127us/step - loss: 5.7843\n",
      "Epoch 183/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8169\n",
      "Epoch 185/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8446\n",
      "Epoch 186/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8514\n",
      "Epoch 187/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8233\n",
      "Epoch 188/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.8659\n",
      "Epoch 189/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8525\n",
      "Epoch 190/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8373\n",
      "Epoch 191/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8212\n",
      "Epoch 192/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7208\n",
      "Epoch 193/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7479\n",
      "Epoch 194/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7671\n",
      "Epoch 195/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7425\n",
      "Epoch 196/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.7850\n",
      "Epoch 197/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7935\n",
      "Epoch 198/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8449\n",
      "Epoch 199/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8918\n",
      "Epoch 200/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7546\n",
      "Epoch 201/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8353\n",
      "Epoch 202/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8166\n",
      "Epoch 203/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8016\n",
      "Epoch 204/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7737\n",
      "Epoch 205/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8117\n",
      "Epoch 206/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7244\n",
      "Epoch 207/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7444\n",
      "Epoch 208/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8062\n",
      "Epoch 209/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8972\n",
      "Epoch 210/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.7689\n",
      "Epoch 211/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8095\n",
      "Epoch 212/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7897\n",
      "Epoch 213/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8647\n",
      "Epoch 214/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8099\n",
      "Epoch 215/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8080\n",
      "Epoch 216/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7858\n",
      "Epoch 217/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7787\n",
      "Epoch 218/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7534\n",
      "Epoch 219/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8776\n",
      "Epoch 220/1000\n",
      "4256/4256 [==============================] - 1s 123us/step - loss: 5.8342\n",
      "Epoch 221/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7359\n",
      "Epoch 222/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7950\n",
      "Epoch 223/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7607\n",
      "Epoch 224/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.7889\n",
      "Epoch 225/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7524\n",
      "Epoch 226/1000\n",
      "4256/4256 [==============================] - 1s 124us/step - loss: 5.7837\n",
      "Epoch 227/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8217\n",
      "Epoch 228/1000\n",
      "4256/4256 [==============================] - 1s 136us/step - loss: 5.8115\n",
      "Epoch 229/1000\n",
      "4256/4256 [==============================] - 1s 124us/step - loss: 5.7481\n",
      "Epoch 230/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8108\n",
      "Epoch 231/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8404\n",
      "Epoch 232/1000\n",
      "4256/4256 [==============================] - 1s 155us/step - loss: 5.8183\n",
      "Epoch 233/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8215\n",
      "Epoch 234/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8167\n",
      "Epoch 235/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.7860\n",
      "Epoch 236/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7901\n",
      "Epoch 237/1000\n",
      "4256/4256 [==============================] - 0s 105us/step - loss: 5.8128\n",
      "Epoch 238/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8805\n",
      "Epoch 239/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7939\n",
      "Epoch 240/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8050\n",
      "Epoch 241/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8102\n",
      "Epoch 242/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8236\n",
      "Epoch 243/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7329\n",
      "Epoch 244/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.7702\n",
      "Epoch 245/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7928\n",
      "Epoch 246/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8267\n",
      "Epoch 247/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7923\n",
      "Epoch 248/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7760\n",
      "Epoch 249/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8316\n",
      "Epoch 250/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8038\n",
      "Epoch 251/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8093\n",
      "Epoch 252/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7699\n",
      "Epoch 253/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7991\n",
      "Epoch 254/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7468\n",
      "Epoch 255/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7825\n",
      "Epoch 256/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7682\n",
      "Epoch 257/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8435\n",
      "Epoch 258/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7571\n",
      "Epoch 259/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8329\n",
      "Epoch 260/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7542\n",
      "Epoch 261/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7963\n",
      "Epoch 262/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7893\n",
      "Epoch 263/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7292\n",
      "Epoch 264/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8298\n",
      "Epoch 265/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8118\n",
      "Epoch 266/1000\n",
      "4256/4256 [==============================] - 1s 141us/step - loss: 5.7555\n",
      "Epoch 267/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7951\n",
      "Epoch 268/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8208\n",
      "Epoch 269/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.8286\n",
      "Epoch 270/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8220\n",
      "Epoch 271/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7744\n",
      "Epoch 272/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8254\n",
      "Epoch 273/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8030\n",
      "Epoch 274/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8228\n",
      "Epoch 275/1000\n",
      "4256/4256 [==============================] - 1s 124us/step - loss: 5.8030\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8137\n",
      "Epoch 277/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8440\n",
      "Epoch 278/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7700\n",
      "Epoch 279/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8163\n",
      "Epoch 280/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7875\n",
      "Epoch 281/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7797\n",
      "Epoch 282/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8043\n",
      "Epoch 283/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8109\n",
      "Epoch 284/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8151\n",
      "Epoch 285/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8201\n",
      "Epoch 286/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8409\n",
      "Epoch 287/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8217\n",
      "Epoch 288/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7902\n",
      "Epoch 289/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7859\n",
      "Epoch 290/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8523\n",
      "Epoch 291/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7892\n",
      "Epoch 292/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7689\n",
      "Epoch 293/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7184\n",
      "Epoch 294/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8034\n",
      "Epoch 295/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8077\n",
      "Epoch 296/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7862\n",
      "Epoch 297/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8285\n",
      "Epoch 298/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8551\n",
      "Epoch 299/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.7551\n",
      "Epoch 300/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8289\n",
      "Epoch 301/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7735\n",
      "Epoch 302/1000\n",
      "4256/4256 [==============================] - 1s 148us/step - loss: 5.8080\n",
      "Epoch 303/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7720\n",
      "Epoch 304/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8105\n",
      "Epoch 305/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7868\n",
      "Epoch 306/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7898\n",
      "Epoch 307/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8457\n",
      "Epoch 308/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7867\n",
      "Epoch 309/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8372\n",
      "Epoch 310/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7633\n",
      "Epoch 311/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8692\n",
      "Epoch 312/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7783\n",
      "Epoch 313/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7933\n",
      "Epoch 314/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7695\n",
      "Epoch 315/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8409\n",
      "Epoch 316/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8004\n",
      "Epoch 317/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8018\n",
      "Epoch 318/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7960\n",
      "Epoch 319/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7721\n",
      "Epoch 320/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7562\n",
      "Epoch 321/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7619\n",
      "Epoch 322/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8676\n",
      "Epoch 323/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7684\n",
      "Epoch 324/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7950\n",
      "Epoch 325/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8301\n",
      "Epoch 326/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7692\n",
      "Epoch 327/1000\n",
      "4256/4256 [==============================] - 1s 131us/step - loss: 5.7244\n",
      "Epoch 328/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.9106\n",
      "Epoch 329/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8298\n",
      "Epoch 330/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8169\n",
      "Epoch 331/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8056\n",
      "Epoch 332/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7764\n",
      "Epoch 333/1000\n",
      "4256/4256 [==============================] - 1s 144us/step - loss: 5.7265\n",
      "Epoch 334/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8048\n",
      "Epoch 335/1000\n",
      "4256/4256 [==============================] - 1s 133us/step - loss: 5.7840\n",
      "Epoch 336/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.7678\n",
      "Epoch 337/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8313\n",
      "Epoch 338/1000\n",
      "4256/4256 [==============================] - 1s 155us/step - loss: 5.8203\n",
      "Epoch 339/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7814\n",
      "Epoch 340/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8358\n",
      "Epoch 341/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7514\n",
      "Epoch 342/1000\n",
      "4256/4256 [==============================] - 1s 126us/step - loss: 5.7343\n",
      "Epoch 343/1000\n",
      "4256/4256 [==============================] - 1s 165us/step - loss: 5.8426\n",
      "Epoch 344/1000\n",
      "4256/4256 [==============================] - 1s 123us/step - loss: 5.8423\n",
      "Epoch 345/1000\n",
      "4256/4256 [==============================] - 1s 130us/step - loss: 5.8278\n",
      "Epoch 346/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7518\n",
      "Epoch 347/1000\n",
      "4256/4256 [==============================] - 1s 128us/step - loss: 5.7316\n",
      "Epoch 348/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.7780\n",
      "Epoch 349/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7904\n",
      "Epoch 350/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8400\n",
      "Epoch 351/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8449\n",
      "Epoch 352/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.8432\n",
      "Epoch 353/1000\n",
      "4256/4256 [==============================] - 1s 149us/step - loss: 5.8378\n",
      "Epoch 354/1000\n",
      "4256/4256 [==============================] - 1s 157us/step - loss: 5.8406\n",
      "Epoch 355/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8354\n",
      "Epoch 356/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8013\n",
      "Epoch 357/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8550\n",
      "Epoch 358/1000\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.398039). Check your callbacks.\n",
      "4256/4256 [==============================] - 1s 204us/step - loss: 5.7863\n",
      "Epoch 359/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7497\n",
      "Epoch 360/1000\n",
      "4256/4256 [==============================] - 1s 170us/step - loss: 5.7431\n",
      "Epoch 361/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7551\n",
      "Epoch 362/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7120\n",
      "Epoch 363/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.7653\n",
      "Epoch 364/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8465\n",
      "Epoch 365/1000\n",
      "4256/4256 [==============================] - 1s 141us/step - loss: 5.7816\n",
      "Epoch 366/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000\n",
      "4256/4256 [==============================] - 0s 105us/step - loss: 5.8488\n",
      "Epoch 368/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7502\n",
      "Epoch 369/1000\n",
      "4256/4256 [==============================] - 1s 134us/step - loss: 5.7796\n",
      "Epoch 370/1000\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.607011). Check your callbacks.\n",
      "4256/4256 [==============================] - 1s 264us/step - loss: 5.8386\n",
      "Epoch 371/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8751\n",
      "Epoch 372/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7927\n",
      "Epoch 373/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7713\n",
      "Epoch 374/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8406\n",
      "Epoch 375/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8520\n",
      "Epoch 376/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8635\n",
      "Epoch 377/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7729\n",
      "Epoch 378/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8488\n",
      "Epoch 379/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7965\n",
      "Epoch 380/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8531\n",
      "Epoch 381/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.9172\n",
      "Epoch 382/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7461\n",
      "Epoch 383/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.8378\n",
      "Epoch 384/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8201\n",
      "Epoch 385/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8024\n",
      "Epoch 386/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7670\n",
      "Epoch 387/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8062\n",
      "Epoch 388/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7484\n",
      "Epoch 389/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7695\n",
      "Epoch 390/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8089\n",
      "Epoch 391/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.8116\n",
      "Epoch 392/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7689\n",
      "Epoch 393/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7955\n",
      "Epoch 394/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8426\n",
      "Epoch 395/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7818\n",
      "Epoch 396/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8039\n",
      "Epoch 397/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.8599\n",
      "Epoch 398/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7568\n",
      "Epoch 399/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7837\n",
      "Epoch 400/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8342\n",
      "Epoch 401/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7704\n",
      "Epoch 402/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7768\n",
      "Epoch 403/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8734\n",
      "Epoch 404/1000\n",
      "4256/4256 [==============================] - 1s 123us/step - loss: 5.7784\n",
      "Epoch 405/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8564\n",
      "Epoch 406/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7899\n",
      "Epoch 407/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7827\n",
      "Epoch 408/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7904\n",
      "Epoch 409/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7499\n",
      "Epoch 410/1000\n",
      "4256/4256 [==============================] - 1s 123us/step - loss: 5.7900\n",
      "Epoch 411/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8386\n",
      "Epoch 412/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8408\n",
      "Epoch 413/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7551\n",
      "Epoch 414/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7928\n",
      "Epoch 415/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8034\n",
      "Epoch 416/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7630\n",
      "Epoch 417/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8452\n",
      "Epoch 418/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7960\n",
      "Epoch 419/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7782\n",
      "Epoch 420/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7704\n",
      "Epoch 421/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7964\n",
      "Epoch 422/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8078\n",
      "Epoch 423/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7967\n",
      "Epoch 424/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8159\n",
      "Epoch 425/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7719\n",
      "Epoch 426/1000\n",
      "4256/4256 [==============================] - 1s 148us/step - loss: 5.8218\n",
      "Epoch 427/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8135\n",
      "Epoch 428/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8231\n",
      "Epoch 429/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8114\n",
      "Epoch 430/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8364\n",
      "Epoch 431/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8300\n",
      "Epoch 432/1000\n",
      "4256/4256 [==============================] - 0s 105us/step - loss: 5.7642\n",
      "Epoch 433/1000\n",
      "4256/4256 [==============================] - 1s 149us/step - loss: 5.8325\n",
      "Epoch 434/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8116\n",
      "Epoch 435/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7785\n",
      "Epoch 436/1000\n",
      "4256/4256 [==============================] - 1s 195us/step - loss: 5.8278\n",
      "Epoch 437/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7627\n",
      "Epoch 438/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8121\n",
      "Epoch 439/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7713\n",
      "Epoch 440/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8221\n",
      "Epoch 441/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7980\n",
      "Epoch 442/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7756\n",
      "Epoch 443/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8615\n",
      "Epoch 444/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8045\n",
      "Epoch 445/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7688\n",
      "Epoch 446/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7659\n",
      "Epoch 447/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8299\n",
      "Epoch 448/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7557\n",
      "Epoch 449/1000\n",
      "4256/4256 [==============================] - 1s 155us/step - loss: 5.7732\n",
      "Epoch 450/1000\n",
      "WARNING:tensorflow:Method on_batch_end() is slow compared to the batch update (0.400044). Check your callbacks.\n",
      "4256/4256 [==============================] - 1s 195us/step - loss: 5.7979\n",
      "Epoch 451/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7897\n",
      "Epoch 452/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7807\n",
      "Epoch 453/1000\n",
      "4256/4256 [==============================] - 1s 123us/step - loss: 5.7902\n",
      "Epoch 454/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8150\n",
      "Epoch 455/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8220\n",
      "Epoch 456/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7654\n",
      "Epoch 458/1000\n",
      "4256/4256 [==============================] - 1s 129us/step - loss: 5.7899\n",
      "Epoch 459/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.7607\n",
      "Epoch 460/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8135\n",
      "Epoch 461/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8037\n",
      "Epoch 462/1000\n",
      "4256/4256 [==============================] - 0s 105us/step - loss: 5.8166\n",
      "Epoch 463/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8475\n",
      "Epoch 464/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7516\n",
      "Epoch 465/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.7770\n",
      "Epoch 466/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8889\n",
      "Epoch 467/1000\n",
      "4256/4256 [==============================] - 1s 132us/step - loss: 5.8606\n",
      "Epoch 468/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7460\n",
      "Epoch 469/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.8362\n",
      "Epoch 470/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8193\n",
      "Epoch 471/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8436\n",
      "Epoch 472/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8437\n",
      "Epoch 473/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7874\n",
      "Epoch 474/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7757\n",
      "Epoch 475/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7734\n",
      "Epoch 476/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8209\n",
      "Epoch 477/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7664\n",
      "Epoch 478/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8027\n",
      "Epoch 479/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8186\n",
      "Epoch 480/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8114\n",
      "Epoch 481/1000\n",
      "4256/4256 [==============================] - 1s 137us/step - loss: 5.7828\n",
      "Epoch 482/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8339\n",
      "Epoch 483/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8287\n",
      "Epoch 484/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8329\n",
      "Epoch 485/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7867\n",
      "Epoch 486/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8304\n",
      "Epoch 487/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7901\n",
      "Epoch 488/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8071\n",
      "Epoch 489/1000\n",
      "4256/4256 [==============================] - 1s 124us/step - loss: 5.8101\n",
      "Epoch 490/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8336\n",
      "Epoch 491/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7391\n",
      "Epoch 492/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8290\n",
      "Epoch 493/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8352\n",
      "Epoch 494/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7719\n",
      "Epoch 495/1000\n",
      "4256/4256 [==============================] - 1s 127us/step - loss: 5.7918\n",
      "Epoch 496/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7925\n",
      "Epoch 497/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8532\n",
      "Epoch 498/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7636\n",
      "Epoch 499/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.8042\n",
      "Epoch 500/1000\n",
      "4256/4256 [==============================] - 1s 139us/step - loss: 5.7922\n",
      "Epoch 501/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.7293\n",
      "Epoch 502/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7725\n",
      "Epoch 503/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7875\n",
      "Epoch 504/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8285\n",
      "Epoch 505/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7640\n",
      "Epoch 506/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7964\n",
      "Epoch 507/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7851\n",
      "Epoch 508/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7712\n",
      "Epoch 509/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8352\n",
      "Epoch 510/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8578\n",
      "Epoch 511/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7859\n",
      "Epoch 512/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8617\n",
      "Epoch 513/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8962\n",
      "Epoch 514/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8802\n",
      "Epoch 515/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8227\n",
      "Epoch 516/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8223\n",
      "Epoch 517/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8088\n",
      "Epoch 518/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8042\n",
      "Epoch 519/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8450\n",
      "Epoch 520/1000\n",
      "4256/4256 [==============================] - 1s 132us/step - loss: 5.8450\n",
      "Epoch 521/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7427\n",
      "Epoch 522/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7568\n",
      "Epoch 523/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7980\n",
      "Epoch 524/1000\n",
      "4256/4256 [==============================] - 1s 159us/step - loss: 5.8264\n",
      "Epoch 525/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8197\n",
      "Epoch 526/1000\n",
      "4256/4256 [==============================] - 1s 117us/step - loss: 5.8487\n",
      "Epoch 527/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7325\n",
      "Epoch 528/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7922\n",
      "Epoch 529/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8018\n",
      "Epoch 530/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8023\n",
      "Epoch 531/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8134\n",
      "Epoch 532/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8327\n",
      "Epoch 533/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7558\n",
      "Epoch 534/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7726\n",
      "Epoch 535/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8344\n",
      "Epoch 536/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7875\n",
      "Epoch 537/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7824\n",
      "Epoch 538/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7802\n",
      "Epoch 539/1000\n",
      "4256/4256 [==============================] - 1s 181us/step - loss: 5.8333\n",
      "Epoch 540/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8379\n",
      "Epoch 541/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7814\n",
      "Epoch 542/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7413\n",
      "Epoch 543/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8440\n",
      "Epoch 544/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8354\n",
      "Epoch 545/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7956\n",
      "Epoch 546/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8029\n",
      "Epoch 547/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8107\n",
      "Epoch 548/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.7743\n",
      "Epoch 549/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4256/4256 [==============================] - 1s 182us/step - loss: 5.7914\n",
      "Epoch 550/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8173\n",
      "Epoch 551/1000\n",
      "4256/4256 [==============================] - 1s 146us/step - loss: 5.8046\n",
      "Epoch 552/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7151\n",
      "Epoch 553/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7803\n",
      "Epoch 554/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7542\n",
      "Epoch 555/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.8105\n",
      "Epoch 556/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7498\n",
      "Epoch 557/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8364\n",
      "Epoch 558/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8271\n",
      "Epoch 559/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.8555\n",
      "Epoch 560/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7631\n",
      "Epoch 561/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7723\n",
      "Epoch 562/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8108\n",
      "Epoch 563/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7982\n",
      "Epoch 564/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.8274\n",
      "Epoch 565/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8200\n",
      "Epoch 566/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7512\n",
      "Epoch 567/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8432\n",
      "Epoch 568/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7969\n",
      "Epoch 569/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7650\n",
      "Epoch 570/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.9022\n",
      "Epoch 571/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7724\n",
      "Epoch 572/1000\n",
      "4256/4256 [==============================] - 1s 155us/step - loss: 5.8359\n",
      "Epoch 573/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7433\n",
      "Epoch 574/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8244\n",
      "Epoch 575/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8208\n",
      "Epoch 576/1000\n",
      "4256/4256 [==============================] - 0s 106us/step - loss: 5.7709\n",
      "Epoch 577/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7790\n",
      "Epoch 578/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7908\n",
      "Epoch 579/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8125\n",
      "Epoch 580/1000\n",
      "4256/4256 [==============================] - 1s 123us/step - loss: 5.8330\n",
      "Epoch 581/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8064\n",
      "Epoch 582/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7439\n",
      "Epoch 583/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8583\n",
      "Epoch 584/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7762\n",
      "Epoch 585/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8248\n",
      "Epoch 586/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7895\n",
      "Epoch 587/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7900\n",
      "Epoch 588/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8462\n",
      "Epoch 589/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8621\n",
      "Epoch 590/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7530\n",
      "Epoch 591/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8069\n",
      "Epoch 592/1000\n",
      "4256/4256 [==============================] - 1s 194us/step - loss: 5.7633\n",
      "Epoch 593/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7586\n",
      "Epoch 594/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7829\n",
      "Epoch 595/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8465\n",
      "Epoch 596/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8296\n",
      "Epoch 597/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.7631\n",
      "Epoch 598/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7855\n",
      "Epoch 599/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8281\n",
      "Epoch 600/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.8260\n",
      "Epoch 601/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7523\n",
      "Epoch 602/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8167\n",
      "Epoch 603/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7829\n",
      "Epoch 604/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8117\n",
      "Epoch 605/1000\n",
      "4256/4256 [==============================] - 1s 182us/step - loss: 5.8342\n",
      "Epoch 606/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.7857\n",
      "Epoch 607/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8017\n",
      "Epoch 608/1000\n",
      "4256/4256 [==============================] - 0s 105us/step - loss: 5.7388\n",
      "Epoch 609/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8387\n",
      "Epoch 610/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8872\n",
      "Epoch 611/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8368\n",
      "Epoch 612/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7328\n",
      "Epoch 613/1000\n",
      "4256/4256 [==============================] - 0s 105us/step - loss: 5.7550\n",
      "Epoch 614/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8386\n",
      "Epoch 615/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7965\n",
      "Epoch 616/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7655\n",
      "Epoch 617/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8177\n",
      "Epoch 618/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8385\n",
      "Epoch 619/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8446\n",
      "Epoch 620/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7393\n",
      "Epoch 621/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7886\n",
      "Epoch 622/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.7858\n",
      "Epoch 623/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7466\n",
      "Epoch 624/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.8189\n",
      "Epoch 625/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7803\n",
      "Epoch 626/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7706\n",
      "Epoch 627/1000\n",
      "4256/4256 [==============================] - 0s 115us/step - loss: 5.8247\n",
      "Epoch 628/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7595\n",
      "Epoch 629/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8208\n",
      "Epoch 630/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8144\n",
      "Epoch 631/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7929\n",
      "Epoch 632/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8626\n",
      "Epoch 633/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7982\n",
      "Epoch 634/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7945\n",
      "Epoch 635/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8018\n",
      "Epoch 636/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8059\n",
      "Epoch 637/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8841\n",
      "Epoch 638/1000\n",
      "4256/4256 [==============================] - 0s 105us/step - loss: 5.8063\n",
      "Epoch 639/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7933\n",
      "Epoch 640/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.8001\n",
      "Epoch 641/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.8039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 642/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8135\n",
      "Epoch 643/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7946\n",
      "Epoch 644/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8195\n",
      "Epoch 645/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8033\n",
      "Epoch 646/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8023\n",
      "Epoch 647/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7381\n",
      "Epoch 648/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.8248\n",
      "Epoch 649/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.8116\n",
      "Epoch 650/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7950\n",
      "Epoch 651/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8487\n",
      "Epoch 652/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8235\n",
      "Epoch 653/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.8132\n",
      "Epoch 654/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7936\n",
      "Epoch 655/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8352\n",
      "Epoch 656/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8338\n",
      "Epoch 657/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.8005\n",
      "Epoch 658/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8458\n",
      "Epoch 659/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8387\n",
      "Epoch 660/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.8747\n",
      "Epoch 661/1000\n",
      "4256/4256 [==============================] - 0s 111us/step - loss: 5.8141\n",
      "Epoch 662/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.8312\n",
      "Epoch 663/1000\n",
      "4256/4256 [==============================] - 1s 117us/step - loss: 5.8296\n",
      "Epoch 664/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7436\n",
      "Epoch 665/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8647\n",
      "Epoch 666/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7898\n",
      "Epoch 667/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7459\n",
      "Epoch 668/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.7813\n",
      "Epoch 669/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7548\n",
      "Epoch 670/1000\n",
      "4256/4256 [==============================] - 1s 120us/step - loss: 5.7825\n",
      "Epoch 671/1000\n",
      "4256/4256 [==============================] - 0s 104us/step - loss: 5.6868\n",
      "Epoch 672/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7945\n",
      "Epoch 673/1000\n",
      "4256/4256 [==============================] - 1s 125us/step - loss: 5.8661\n",
      "Epoch 674/1000\n",
      "4256/4256 [==============================] - 1s 123us/step - loss: 5.7791\n",
      "Epoch 675/1000\n",
      "4256/4256 [==============================] - 1s 119us/step - loss: 5.7369\n",
      "Epoch 676/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7483\n",
      "Epoch 677/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7771\n",
      "Epoch 678/1000\n",
      "4256/4256 [==============================] - 1s 147us/step - loss: 5.7842\n",
      "Epoch 679/1000\n",
      "4256/4256 [==============================] - 0s 116us/step - loss: 5.7743\n",
      "Epoch 680/1000\n",
      "4256/4256 [==============================] - 1s 121us/step - loss: 5.7945\n",
      "Epoch 681/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7285\n",
      "Epoch 682/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7817\n",
      "Epoch 683/1000\n",
      "4256/4256 [==============================] - 0s 107us/step - loss: 5.8290\n",
      "Epoch 684/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7489\n",
      "Epoch 685/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7444\n",
      "Epoch 686/1000\n",
      "4256/4256 [==============================] - 1s 122us/step - loss: 5.7709\n",
      "Epoch 687/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8432\n",
      "Epoch 688/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8614\n",
      "Epoch 689/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7979\n",
      "Epoch 690/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.7477\n",
      "Epoch 691/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8156\n",
      "Epoch 692/1000\n",
      "4256/4256 [==============================] - 1s 124us/step - loss: 5.8133\n",
      "Epoch 693/1000\n",
      "4256/4256 [==============================] - 0s 114us/step - loss: 5.8035\n",
      "Epoch 694/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.7929\n",
      "Epoch 695/1000\n",
      "4256/4256 [==============================] - 0s 113us/step - loss: 5.8438\n",
      "Epoch 696/1000\n",
      "4256/4256 [==============================] - 0s 112us/step - loss: 5.7546\n",
      "Epoch 697/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7563\n",
      "Epoch 698/1000\n",
      "4256/4256 [==============================] - 1s 118us/step - loss: 5.7573\n",
      "Epoch 699/1000\n",
      "4256/4256 [==============================] - 0s 108us/step - loss: 5.7621\n",
      "Epoch 700/1000\n",
      "4256/4256 [==============================] - 1s 126us/step - loss: 5.8040\n",
      "Epoch 701/1000\n",
      "4256/4256 [==============================] - 0s 117us/step - loss: 5.8363\n",
      "Epoch 702/1000\n",
      "4256/4256 [==============================] - 1s 124us/step - loss: 5.8142\n",
      "Epoch 703/1000\n",
      "4256/4256 [==============================] - 0s 110us/step - loss: 5.7709\n",
      "Epoch 704/1000\n",
      "4256/4256 [==============================] - 0s 109us/step - loss: 5.7884\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0af5860108fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_to_use\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtbCallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./logs/vae/RMSprop/%s'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcfg_net_autoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_to_use\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_to_use\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtbCallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwinsound\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\windows\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\windows\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    212\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\windows\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2978\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2980\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\windows\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for key in my_dict:\n",
    "for key in [23]:\n",
    "    data_to_use = my_dict[key]\n",
    "    tbCallback = tf.keras.callbacks.TensorBoard(log_dir='./logs/vae/RMSprop/%s'%(key), histogram_freq=0)\n",
    "    cfg_net_autoencoder.fit(x=data_to_use,y=data_to_use,batch_size=10000,epochs=1000, callbacks=[tbCallback])\n",
    "\n",
    "import winsound\n",
    "frequency = 2500 \n",
    "duration = 500 \n",
    "winsound.Beep(frequency, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
